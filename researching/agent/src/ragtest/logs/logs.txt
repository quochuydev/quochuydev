2025-09-14 19:47:47.0665 - INFO - graphrag.cli.index - Logging enabled at /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/logs/logs.txt
2025-09-14 19:47:52.0410 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-09-14 19:47:53.0577 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-09-14 19:47:53.0577 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-09-14 19:47:53.0579 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-09-14 19:47:53.0582 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-09-14 19:47:53.0582 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-09-14 19:47:53.0582 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/input
2025-09-14 19:47:53.0582 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/output
2025-09-14 19:47:53.0583 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-09-14 19:47:53.0585 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-09-14 19:47:53.0586 - INFO - graphrag.index.input.factory - loading input from root_dir=/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/input
2025-09-14 19:47:53.0586 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-09-14 19:47:53.0586 - INFO - graphrag.storage.file_pipeline_storage - search /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/input for files matching .*\.txt$
2025-09-14 19:47:53.0591 - INFO - graphrag.index.input.util - Found 1 InputFileType.text files, loading 1
2025-09-14 19:47:53.0592 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.text rows: 1
2025-09-14 19:47:53.0592 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 1
2025-09-14 19:47:53.0614 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-09-14 19:47:53.0618 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-09-14 19:47:53.0618 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-09-14 19:47:53.0637 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 1 documents
2025-09-14 19:47:53.0659 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/1
2025-09-14 19:47:53.0668 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-09-14 19:47:53.0668 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-09-14 19:47:53.0673 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-09-14 19:47:53.0673 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-09-14 19:47:53.0675 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-14 19:47:53.0684 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-09-14 19:47:53.0684 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-09-14 19:47:53.0687 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-09-14 19:47:53.0687 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-14 19:48:20.0816 - INFO - graphrag.logger.progress - extract graph progress: 1/42
2025-09-14 19:49:20.0317 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2789. Please try again in 5.578s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:20.0322 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2789. Please try again in 5.578s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:20.0324 - INFO - graphrag.logger.progress - extract graph progress: 2/42
2025-09-14 19:49:24.0841 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3004. Please try again in 6.008s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:24.0847 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3004. Please try again in 6.008s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:24.0850 - INFO - graphrag.logger.progress - extract graph progress: 3/42
2025-09-14 19:49:25.0476 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3018. Please try again in 6.036s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:25.0482 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3018. Please try again in 6.036s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:25.0484 - INFO - graphrag.logger.progress - extract graph progress: 4/42
2025-09-14 19:49:27.0578 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3056. Please try again in 6.112s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:27.0581 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3056. Please try again in 6.112s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:27.0584 - INFO - graphrag.logger.progress - extract graph progress: 5/42
2025-09-14 19:49:28.0478 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3064. Please try again in 6.128s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:28.0484 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3064. Please try again in 6.128s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:28.0486 - INFO - graphrag.logger.progress - extract graph progress: 6/42
2025-09-14 19:49:29.0114 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3091. Please try again in 6.182s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:29.0117 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3091. Please try again in 6.182s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:29.0119 - INFO - graphrag.logger.progress - extract graph progress: 7/42
2025-09-14 19:49:30.0524 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3187. Please try again in 6.374s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:30.0528 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3187. Please try again in 6.374s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:30.0531 - INFO - graphrag.logger.progress - extract graph progress: 8/42
2025-09-14 19:49:31.0640 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3146. Please try again in 6.292s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:31.0646 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3146. Please try again in 6.292s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:31.0650 - INFO - graphrag.logger.progress - extract graph progress: 9/42
2025-09-14 19:49:32.0160 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3156. Please try again in 6.312s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:32.0163 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3156. Please try again in 6.312s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:32.0167 - INFO - graphrag.logger.progress - extract graph progress: 10/42
2025-09-14 19:49:32.0535 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3217. Please try again in 6.434s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:32.0540 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3217. Please try again in 6.434s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:32.0544 - INFO - graphrag.logger.progress - extract graph progress: 11/42
2025-09-14 19:49:32.0837 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3184. Please try again in 6.368s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:32.0842 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3184. Please try again in 6.368s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:32.0847 - INFO - graphrag.logger.progress - extract graph progress: 12/42
2025-09-14 19:49:34.0130 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3116. Please try again in 6.232s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:34.0133 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3116. Please try again in 6.232s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:34.0135 - INFO - graphrag.logger.progress - extract graph progress: 13/42
2025-09-14 19:49:35.0056 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3229. Please try again in 6.458s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:35.0059 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3229. Please try again in 6.458s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:35.0061 - INFO - graphrag.logger.progress - extract graph progress: 14/42
2025-09-14 19:49:35.0392 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3203. Please try again in 6.406s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:35.0397 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3203. Please try again in 6.406s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:35.0400 - INFO - graphrag.logger.progress - extract graph progress: 15/42
2025-09-14 19:49:35.0422 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3201. Please try again in 6.402s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:35.0428 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3201. Please try again in 6.402s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:35.0430 - INFO - graphrag.logger.progress - extract graph progress: 16/42
2025-09-14 19:49:36.0027 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3210. Please try again in 6.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:36.0031 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3210. Please try again in 6.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:36.0034 - INFO - graphrag.logger.progress - extract graph progress: 17/42
2025-09-14 19:49:37.0150 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3221. Please try again in 6.442s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:37.0156 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3221. Please try again in 6.442s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:37.0160 - INFO - graphrag.logger.progress - extract graph progress: 18/42
2025-09-14 19:49:37.0376 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3276. Please try again in 6.552s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:37.0378 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3276. Please try again in 6.552s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:37.0381 - INFO - graphrag.logger.progress - extract graph progress: 19/42
2025-09-14 19:49:41.0045 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3349. Please try again in 6.698s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:41.0048 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3349. Please try again in 6.698s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:41.0050 - INFO - graphrag.logger.progress - extract graph progress: 20/42
2025-09-14 19:49:42.0434 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3430. Please try again in 6.86s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:42.0436 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3430. Please try again in 6.86s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:42.0438 - INFO - graphrag.logger.progress - extract graph progress: 21/42
2025-09-14 19:49:42.0757 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3374. Please try again in 6.748s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:42.0762 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3374. Please try again in 6.748s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:42.0765 - INFO - graphrag.logger.progress - extract graph progress: 22/42
2025-09-14 19:49:43.0456 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3377. Please try again in 6.754s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:43.0464 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3377. Please try again in 6.754s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:43.0469 - INFO - graphrag.logger.progress - extract graph progress: 23/42
2025-09-14 19:49:44.0009 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3452. Please try again in 6.904s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:44.0015 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3452. Please try again in 6.904s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:44.0019 - INFO - graphrag.logger.progress - extract graph progress: 24/42
2025-09-14 19:49:45.0171 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3419. Please try again in 6.838s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:45.0176 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3419. Please try again in 6.838s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:45.0178 - INFO - graphrag.logger.progress - extract graph progress: 25/42
2025-09-14 19:49:55.0892 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3632. Please try again in 7.264s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:55.0895 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3632. Please try again in 7.264s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:49:55.0897 - INFO - graphrag.logger.progress - extract graph progress: 26/42
2025-09-14 19:50:19.0391 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2841. Please try again in 5.682s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:19.0396 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2841. Please try again in 5.682s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:19.0399 - INFO - graphrag.logger.progress - extract graph progress: 27/42
2025-09-14 19:50:20.0104 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2792. Please try again in 5.584s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:20.0109 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2792. Please try again in 5.584s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:20.0112 - INFO - graphrag.logger.progress - extract graph progress: 28/42
2025-09-14 19:50:20.0586 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2832. Please try again in 5.664s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:20.0591 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2832. Please try again in 5.664s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:20.0594 - INFO - graphrag.logger.progress - extract graph progress: 29/42
2025-09-14 19:50:26.0154 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2746. Please try again in 5.492s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:26.0158 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2746. Please try again in 5.492s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:26.0161 - INFO - graphrag.logger.progress - extract graph progress: 30/42
2025-09-14 19:50:26.0508 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2770. Please try again in 5.54s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:26.0511 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2770. Please try again in 5.54s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:26.0513 - INFO - graphrag.logger.progress - extract graph progress: 31/42
2025-09-14 19:50:26.0697 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2804. Please try again in 5.608s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:26.0701 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2804. Please try again in 5.608s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:26.0703 - INFO - graphrag.logger.progress - extract graph progress: 32/42
2025-09-14 19:50:26.0734 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2813. Please try again in 5.626s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:26.0738 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2813. Please try again in 5.626s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:26.0740 - INFO - graphrag.logger.progress - extract graph progress: 33/42
2025-09-14 19:50:26.0806 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2787. Please try again in 5.574s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:26.0809 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 2787. Please try again in 5.574s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:26.0812 - INFO - graphrag.logger.progress - extract graph progress: 34/42
2025-09-14 19:50:33.0112 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3022. Please try again in 6.044s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:33.0116 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3022. Please try again in 6.044s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:33.0119 - INFO - graphrag.logger.progress - extract graph progress: 35/42
2025-09-14 19:50:34.0307 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3001. Please try again in 6.002s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:34.0310 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3001. Please try again in 6.002s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:50:34.0312 - INFO - graphrag.logger.progress - extract graph progress: 36/42
2025-09-14 19:50:58.0559 - INFO - graphrag.logger.progress - extract graph progress: 37/42
2025-09-14 19:51:02.0475 - INFO - graphrag.logger.progress - extract graph progress: 38/42
2025-09-14 19:51:06.0811 - INFO - graphrag.logger.progress - extract graph progress: 39/42
2025-09-14 19:51:18.0666 - INFO - graphrag.logger.progress - extract graph progress: 40/42
2025-09-14 19:51:18.0794 - INFO - graphrag.logger.progress - extract graph progress: 41/42
2025-09-14 19:51:18.0836 - INFO - graphrag.logger.progress - extract graph progress: 42/42
2025-09-14 19:51:18.0890 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 1/87
2025-09-14 19:51:18.0890 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 2/87
2025-09-14 19:51:18.0890 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 3/87
2025-09-14 19:51:18.0890 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 4/87
2025-09-14 19:51:18.0890 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 5/87
2025-09-14 19:51:18.0891 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 6/87
2025-09-14 19:51:18.0891 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 7/87
2025-09-14 19:51:18.0891 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 8/87
2025-09-14 19:51:18.0891 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 9/87
2025-09-14 19:51:18.0891 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 10/87
2025-09-14 19:51:18.0891 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 11/87
2025-09-14 19:51:18.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 12/87
2025-09-14 19:51:18.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 13/87
2025-09-14 19:51:18.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 14/87
2025-09-14 19:51:18.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 15/87
2025-09-14 19:51:18.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 16/87
2025-09-14 19:51:18.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 17/87
2025-09-14 19:51:18.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 18/87
2025-09-14 19:51:18.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 19/87
2025-09-14 19:51:18.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 20/87
2025-09-14 19:51:18.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 21/87
2025-09-14 19:51:18.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 22/87
2025-09-14 19:51:18.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 23/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 24/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 25/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 26/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 27/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 28/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 29/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 30/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 31/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 32/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 33/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 34/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 35/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 36/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 37/87
2025-09-14 19:51:18.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 38/87
2025-09-14 19:51:27.0499 - ERROR - graphrag.index.run.run_pipeline - error running workflow extract_graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/run/run_pipeline.py", line 108, in _run_pipeline
    result = await workflow_function(config, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/workflows/extract_graph.py", line 50, in run_workflow
    entities, relationships, raw_entities, raw_relationships = await extract_graph(
                                                               ^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/workflows/extract_graph.py", line 123, in extract_graph
    entities, relationships = await get_summarized_entities_relationships(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/workflows/extract_graph.py", line 144, in get_summarized_entities_relationships
    entity_summaries, relationship_summaries = await summarize_descriptions(
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/summarize_descriptions.py", line 108, in summarize_descriptions
    return await get_summarized(entities_df, relationships_df, semaphore)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/summarize_descriptions.py", line 60, in get_summarized
    node_results = await asyncio.gather(*node_futures)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/summarize_descriptions.py", line 102, in do_summarize_descriptions
    results = await strategy_exec(id, descriptions, cache, strategy_config)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/graph_intelligence_strategy.py", line 38, in run_graph_intelligence
    return await run_summarize_descriptions(llm, id, descriptions, args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/graph_intelligence_strategy.py", line 64, in run_summarize_descriptions
    result = await extractor(id=id, descriptions=descriptions)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/description_summary_extractor.py", line 66, in __call__
    result = await self._summarize_descriptions(id, descriptions)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/description_summary_extractor.py", line 103, in _summarize_descriptions
    result = await self._summarize_descriptions_with_llm(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/description_summary_extractor.py", line 122, in _summarize_descriptions_with_llm
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 259. Please try again in 518ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 19:51:27.0504 - ERROR - graphrag.api.index - Workflow extract_graph completed with errors
2025-09-14 19:51:27.0511 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-09-14 21:05:25.0987 - INFO - graphrag.cli.index - Logging enabled at /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/logs/logs.txt
2025-09-14 21:05:26.0622 - ERROR - graphrag.language_model.providers.fnllm.utils - Error Invoking LLM
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-09-14 21:05:26.0624 - ERROR - graphrag.index.validate_config - LLM configuration error detected. Exiting...
Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-09-14 21:07:22.0886 - INFO - graphrag.cli.index - Logging enabled at /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/logs/logs.txt
2025-09-14 21:07:24.0245 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-09-14 21:07:25.0224 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-09-14 21:07:25.0225 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-09-14 21:07:25.0226 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-09-14 21:07:25.0228 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-09-14 21:07:25.0229 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-09-14 21:07:25.0229 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/input
2025-09-14 21:07:25.0229 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/output
2025-09-14 21:07:25.0232 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-09-14 21:07:25.0234 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-09-14 21:07:25.0234 - INFO - graphrag.index.input.factory - loading input from root_dir=/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/input
2025-09-14 21:07:25.0234 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-09-14 21:07:25.0235 - INFO - graphrag.storage.file_pipeline_storage - search /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/input for files matching .*\.txt$
2025-09-14 21:07:25.0241 - INFO - graphrag.index.input.util - Found 1 InputFileType.text files, loading 1
2025-09-14 21:07:25.0242 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.text rows: 1
2025-09-14 21:07:25.0242 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 1
2025-09-14 21:07:25.0272 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-09-14 21:07:25.0278 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-09-14 21:07:25.0278 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-09-14 21:07:25.0303 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 1 documents
2025-09-14 21:07:25.0324 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/1
2025-09-14 21:07:25.0334 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-09-14 21:07:25.0334 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-09-14 21:07:25.0339 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-09-14 21:07:25.0340 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-09-14 21:07:25.0341 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-14 21:07:25.0350 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-09-14 21:07:25.0350 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-09-14 21:07:25.0353 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-09-14 21:07:25.0353 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-14 21:07:27.0722 - INFO - graphrag.logger.progress - extract graph progress: 1/42
2025-09-14 21:07:29.0128 - INFO - graphrag.logger.progress - extract graph progress: 2/42
2025-09-14 21:07:29.0267 - INFO - graphrag.logger.progress - extract graph progress: 3/42
2025-09-14 21:07:29.0285 - INFO - graphrag.logger.progress - extract graph progress: 4/42
2025-09-14 21:07:29.0297 - INFO - graphrag.logger.progress - extract graph progress: 5/42
2025-09-14 21:07:29.0302 - INFO - graphrag.logger.progress - extract graph progress: 6/42
2025-09-14 21:07:29.0333 - INFO - graphrag.logger.progress - extract graph progress: 7/42
2025-09-14 21:07:29.0365 - INFO - graphrag.logger.progress - extract graph progress: 8/42
2025-09-14 21:07:29.0478 - INFO - graphrag.logger.progress - extract graph progress: 9/42
2025-09-14 21:07:29.0489 - INFO - graphrag.logger.progress - extract graph progress: 10/42
2025-09-14 21:07:29.0492 - INFO - graphrag.logger.progress - extract graph progress: 11/42
2025-09-14 21:07:29.0495 - INFO - graphrag.logger.progress - extract graph progress: 12/42
2025-09-14 21:07:29.0512 - INFO - graphrag.logger.progress - extract graph progress: 13/42
2025-09-14 21:07:29.0515 - INFO - graphrag.logger.progress - extract graph progress: 14/42
2025-09-14 21:07:29.0548 - INFO - graphrag.logger.progress - extract graph progress: 15/42
2025-09-14 21:07:29.0551 - INFO - graphrag.logger.progress - extract graph progress: 16/42
2025-09-14 21:07:29.0614 - INFO - graphrag.logger.progress - extract graph progress: 17/42
2025-09-14 21:07:29.0618 - INFO - graphrag.logger.progress - extract graph progress: 18/42
2025-09-14 21:07:29.0641 - INFO - graphrag.logger.progress - extract graph progress: 19/42
2025-09-14 21:07:29.0678 - INFO - graphrag.logger.progress - extract graph progress: 20/42
2025-09-14 21:07:29.0688 - INFO - graphrag.logger.progress - extract graph progress: 21/42
2025-09-14 21:07:29.0693 - INFO - graphrag.logger.progress - extract graph progress: 22/42
2025-09-14 21:07:29.0836 - INFO - graphrag.logger.progress - extract graph progress: 23/42
2025-09-14 21:07:29.0852 - INFO - graphrag.logger.progress - extract graph progress: 24/42
2025-09-14 21:07:29.0920 - INFO - graphrag.logger.progress - extract graph progress: 25/42
2025-09-14 21:07:29.0940 - INFO - graphrag.logger.progress - extract graph progress: 26/42
2025-09-14 21:07:30.0055 - INFO - graphrag.logger.progress - extract graph progress: 27/42
2025-09-14 21:07:30.0072 - INFO - graphrag.logger.progress - extract graph progress: 28/42
2025-09-14 21:07:30.0140 - INFO - graphrag.logger.progress - extract graph progress: 29/42
2025-09-14 21:07:30.0548 - INFO - graphrag.logger.progress - extract graph progress: 30/42
2025-09-14 21:07:31.0675 - INFO - graphrag.logger.progress - extract graph progress: 31/42
2025-09-14 21:07:56.0607 - INFO - graphrag.logger.progress - extract graph progress: 32/42
2025-09-14 21:07:57.0586 - INFO - graphrag.logger.progress - extract graph progress: 33/42
2025-09-14 21:07:58.0513 - INFO - graphrag.logger.progress - extract graph progress: 34/42
2025-09-14 21:08:15.0311 - INFO - graphrag.logger.progress - extract graph progress: 35/42
2025-09-14 21:08:18.0608 - INFO - graphrag.logger.progress - extract graph progress: 36/42
2025-09-14 21:08:19.0510 - INFO - graphrag.logger.progress - extract graph progress: 37/42
2025-09-14 21:08:19.0516 - INFO - graphrag.logger.progress - extract graph progress: 38/42
2025-09-14 21:08:20.0762 - INFO - graphrag.logger.progress - extract graph progress: 39/42
2025-09-14 21:08:35.0487 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3324. Please try again in 6.648s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 21:08:35.0493 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3324. Please try again in 6.648s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 21:08:35.0495 - INFO - graphrag.logger.progress - extract graph progress: 40/42
2025-09-14 21:08:41.0559 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3222. Please try again in 6.444s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 21:08:41.0564 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3222. Please try again in 6.444s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 21:08:41.0567 - INFO - graphrag.logger.progress - extract graph progress: 41/42
2025-09-14 21:08:42.0090 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3293. Please try again in 6.586s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 21:08:42.0095 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 3293. Please try again in 6.586s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 21:08:42.0098 - INFO - graphrag.logger.progress - extract graph progress: 42/42
2025-09-14 21:08:42.0145 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 1/237
2025-09-14 21:08:42.0145 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 2/237
2025-09-14 21:08:42.0145 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 3/237
2025-09-14 21:08:42.0145 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 4/237
2025-09-14 21:08:42.0145 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 5/237
2025-09-14 21:08:42.0145 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 6/237
2025-09-14 21:08:42.0145 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 7/237
2025-09-14 21:08:42.0146 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 8/237
2025-09-14 21:08:42.0146 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 9/237
2025-09-14 21:08:42.0147 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 10/237
2025-09-14 21:08:42.0149 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 11/237
2025-09-14 21:08:42.0149 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 12/237
2025-09-14 21:08:42.0149 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 13/237
2025-09-14 21:08:42.0149 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 14/237
2025-09-14 21:08:42.0149 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 15/237
2025-09-14 21:08:42.0149 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 16/237
2025-09-14 21:08:42.0149 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 17/237
2025-09-14 21:08:42.0149 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 18/237
2025-09-14 21:08:42.0150 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 19/237
2025-09-14 21:08:42.0150 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 20/237
2025-09-14 21:08:42.0150 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 21/237
2025-09-14 21:08:42.0150 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 22/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 23/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 24/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 25/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 26/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 27/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 28/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 29/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 30/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 31/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 32/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 33/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 34/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 35/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 36/237
2025-09-14 21:08:42.0151 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 37/237
2025-09-14 21:08:42.0152 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 38/237
2025-09-14 21:08:42.0152 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 39/237
2025-09-14 21:08:42.0152 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 40/237
2025-09-14 21:08:42.0152 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 41/237
2025-09-14 21:08:42.0152 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 42/237
2025-09-14 21:08:42.0152 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 43/237
2025-09-14 21:08:42.0152 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 44/237
2025-09-14 21:08:42.0152 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 45/237
2025-09-14 21:08:48.0679 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 46/237
2025-09-14 21:08:48.0679 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 47/237
2025-09-14 21:08:48.0679 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 48/237
2025-09-14 21:08:48.0680 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 49/237
2025-09-14 21:08:48.0680 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 50/237
2025-09-14 21:08:48.0680 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 51/237
2025-09-14 21:08:48.0680 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 52/237
2025-09-14 21:08:48.0680 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 53/237
2025-09-14 21:08:52.0821 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 54/237
2025-09-14 21:08:52.0822 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 55/237
2025-09-14 21:08:52.0822 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 56/237
2025-09-14 21:08:52.0822 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 57/237
2025-09-14 21:08:52.0823 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 58/237
2025-09-14 21:08:52.0823 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 59/237
2025-09-14 21:08:52.0823 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 60/237
2025-09-14 21:08:52.0824 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 61/237
2025-09-14 21:08:52.0824 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 62/237
2025-09-14 21:08:52.0824 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 63/237
2025-09-14 21:08:52.0825 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 64/237
2025-09-14 21:08:52.0825 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 65/237
2025-09-14 21:08:52.0825 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 66/237
2025-09-14 21:08:52.0825 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 67/237
2025-09-14 21:08:52.0825 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 68/237
2025-09-14 21:08:52.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 69/237
2025-09-14 21:08:52.0950 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 70/237
2025-09-14 21:08:52.0950 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 71/237
2025-09-14 21:08:52.0950 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 72/237
2025-09-14 21:08:52.0950 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 73/237
2025-09-14 21:08:52.0951 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 74/237
2025-09-14 21:08:52.0951 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 75/237
2025-09-14 21:08:53.0072 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 76/237
2025-09-14 21:08:53.0218 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 77/237
2025-09-14 21:08:53.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 78/237
2025-09-14 21:08:53.0873 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 79/237
2025-09-14 21:08:54.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 80/237
2025-09-14 21:08:54.0279 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 81/237
2025-09-14 21:08:54.0332 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 82/237
2025-09-14 21:08:54.0987 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 83/237
2025-09-14 21:08:55.0001 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 84/237
2025-09-14 21:08:55.0033 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 85/237
2025-09-14 21:08:55.0157 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 86/237
2025-09-14 21:08:55.0604 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 87/237
2025-09-14 21:08:55.0703 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 88/237
2025-09-14 21:08:56.0051 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 89/237
2025-09-14 21:08:56.0188 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 90/237
2025-09-14 21:08:56.0362 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 91/237
2025-09-14 21:08:57.0036 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 92/237
2025-09-14 21:08:58.0603 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 93/237
2025-09-14 21:08:58.0960 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 94/237
2025-09-14 21:08:58.0989 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 95/237
2025-09-14 21:08:59.0088 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 96/237
2025-09-14 21:09:00.0011 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 97/237
2025-09-14 21:09:01.0410 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 98/237
2025-09-14 21:09:01.0689 - ERROR - graphrag.index.run.run_pipeline - error running workflow extract_graph
Traceback (most recent call last):
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/run/run_pipeline.py", line 108, in _run_pipeline
    result = await workflow_function(config, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/workflows/extract_graph.py", line 50, in run_workflow
    entities, relationships, raw_entities, raw_relationships = await extract_graph(
                                                               ^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/workflows/extract_graph.py", line 123, in extract_graph
    entities, relationships = await get_summarized_entities_relationships(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/workflows/extract_graph.py", line 144, in get_summarized_entities_relationships
    entity_summaries, relationship_summaries = await summarize_descriptions(
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/summarize_descriptions.py", line 108, in summarize_descriptions
    return await get_summarized(entities_df, relationships_df, semaphore)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/summarize_descriptions.py", line 60, in get_summarized
    node_results = await asyncio.gather(*node_futures)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/summarize_descriptions.py", line 102, in do_summarize_descriptions
    results = await strategy_exec(id, descriptions, cache, strategy_config)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/graph_intelligence_strategy.py", line 38, in run_graph_intelligence
    return await run_summarize_descriptions(llm, id, descriptions, args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/graph_intelligence_strategy.py", line 64, in run_summarize_descriptions
    result = await extractor(id=id, descriptions=descriptions)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/description_summary_extractor.py", line 66, in __call__
    result = await self._summarize_descriptions(id, descriptions)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/description_summary_extractor.py", line 103, in _summarize_descriptions
    result = await self._summarize_descriptions_with_llm(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/index/operations/summarize_descriptions/description_summary_extractor.py", line 122, in _summarize_descriptions_with_llm
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 141, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 173, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/silentium/Projects/github/quochuydev/researching/agent/src/graphrag-env/lib/python3.12/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-iR7Njke0Sm7nDNP2aZSAQNPl on tokens per min (TPM): Limit 30000, Used 30000, Requested 245. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-09-14 21:09:01.0697 - ERROR - graphrag.api.index - Workflow extract_graph completed with errors
2025-09-14 21:09:01.0699 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-09-14 21:37:06.0810 - INFO - graphrag.cli.index - Logging enabled at /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/logs/logs.txt
2025-09-14 21:37:07.0943 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-09-14 21:37:09.0523 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-09-14 21:37:09.0523 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-09-14 21:37:09.0525 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4.1-mini",
            "encoding_model": "o200k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-09-14 21:37:09.0526 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-09-14 21:37:09.0526 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-09-14 21:37:09.0526 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/input
2025-09-14 21:37:09.0526 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/output
2025-09-14 21:37:09.0528 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-09-14 21:37:09.0531 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-09-14 21:37:09.0531 - INFO - graphrag.index.input.factory - loading input from root_dir=/Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/input
2025-09-14 21:37:09.0531 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-09-14 21:37:09.0531 - INFO - graphrag.storage.file_pipeline_storage - search /Users/silentium/Projects/github/quochuydev/researching/agent/src/ragtest/input for files matching .*\.txt$
2025-09-14 21:37:09.0536 - INFO - graphrag.index.input.util - Found 1 InputFileType.text files, loading 1
2025-09-14 21:37:09.0537 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.text rows: 1
2025-09-14 21:37:09.0537 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 1
2025-09-14 21:37:09.0559 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-09-14 21:37:09.0564 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-09-14 21:37:09.0565 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-09-14 21:37:09.0581 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 1 documents
2025-09-14 21:37:09.0611 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/1
2025-09-14 21:37:09.0620 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-09-14 21:37:09.0620 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-09-14 21:37:09.0626 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-09-14 21:37:09.0627 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-09-14 21:37:09.0629 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-14 21:37:09.0638 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-09-14 21:37:09.0638 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-09-14 21:37:09.0641 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-09-14 21:37:09.0642 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-14 21:37:32.0832 - INFO - graphrag.logger.progress - extract graph progress: 1/42
2025-09-14 21:37:33.0305 - INFO - graphrag.logger.progress - extract graph progress: 2/42
2025-09-14 21:37:35.0174 - INFO - graphrag.logger.progress - extract graph progress: 3/42
2025-09-14 21:37:38.0241 - INFO - graphrag.logger.progress - extract graph progress: 4/42
2025-09-14 21:37:39.0023 - INFO - graphrag.logger.progress - extract graph progress: 5/42
2025-09-14 21:37:40.0767 - INFO - graphrag.logger.progress - extract graph progress: 6/42
2025-09-14 21:37:40.0859 - INFO - graphrag.logger.progress - extract graph progress: 7/42
2025-09-14 21:37:41.0490 - INFO - graphrag.logger.progress - extract graph progress: 8/42
2025-09-14 21:37:41.0507 - INFO - graphrag.logger.progress - extract graph progress: 9/42
2025-09-14 21:37:41.0663 - INFO - graphrag.logger.progress - extract graph progress: 10/42
2025-09-14 21:37:41.0795 - INFO - graphrag.logger.progress - extract graph progress: 11/42
2025-09-14 21:37:41.0848 - INFO - graphrag.logger.progress - extract graph progress: 12/42
2025-09-14 21:37:42.0650 - INFO - graphrag.logger.progress - extract graph progress: 13/42
2025-09-14 21:37:43.0298 - INFO - graphrag.logger.progress - extract graph progress: 14/42
2025-09-14 21:37:44.0252 - INFO - graphrag.logger.progress - extract graph progress: 15/42
2025-09-14 21:37:44.0665 - INFO - graphrag.logger.progress - extract graph progress: 16/42
2025-09-14 21:37:45.0929 - INFO - graphrag.logger.progress - extract graph progress: 17/42
2025-09-14 21:37:47.0173 - INFO - graphrag.logger.progress - extract graph progress: 18/42
2025-09-14 21:37:47.0352 - INFO - graphrag.logger.progress - extract graph progress: 19/42
2025-09-14 21:37:48.0508 - INFO - graphrag.logger.progress - extract graph progress: 20/42
2025-09-14 21:37:48.0791 - INFO - graphrag.logger.progress - extract graph progress: 21/42
2025-09-14 21:37:49.0902 - INFO - graphrag.logger.progress - extract graph progress: 22/42
2025-09-14 21:37:50.0407 - INFO - graphrag.logger.progress - extract graph progress: 23/42
2025-09-14 21:37:50.0915 - INFO - graphrag.logger.progress - extract graph progress: 24/42
2025-09-14 21:37:51.0004 - INFO - graphrag.logger.progress - extract graph progress: 25/42
2025-09-14 21:37:51.0286 - INFO - graphrag.logger.progress - extract graph progress: 26/42
2025-09-14 21:37:51.0771 - INFO - graphrag.logger.progress - extract graph progress: 27/42
2025-09-14 21:37:51.0830 - INFO - graphrag.logger.progress - extract graph progress: 28/42
2025-09-14 21:37:52.0750 - INFO - graphrag.logger.progress - extract graph progress: 29/42
2025-09-14 21:37:53.0064 - INFO - graphrag.logger.progress - extract graph progress: 30/42
2025-09-14 21:37:53.0224 - INFO - graphrag.logger.progress - extract graph progress: 31/42
2025-09-14 21:37:54.0572 - INFO - graphrag.logger.progress - extract graph progress: 32/42
2025-09-14 21:37:55.0794 - INFO - graphrag.logger.progress - extract graph progress: 33/42
2025-09-14 21:37:56.0178 - INFO - graphrag.logger.progress - extract graph progress: 34/42
2025-09-14 21:37:57.0283 - INFO - graphrag.logger.progress - extract graph progress: 35/42
2025-09-14 21:37:57.0478 - INFO - graphrag.logger.progress - extract graph progress: 36/42
2025-09-14 21:37:58.0573 - INFO - graphrag.logger.progress - extract graph progress: 37/42
2025-09-14 21:38:01.0310 - INFO - graphrag.logger.progress - extract graph progress: 38/42
2025-09-14 21:38:01.0933 - INFO - graphrag.logger.progress - extract graph progress: 39/42
2025-09-14 21:38:03.0547 - INFO - graphrag.logger.progress - extract graph progress: 40/42
2025-09-14 21:38:04.0587 - INFO - graphrag.logger.progress - extract graph progress: 41/42
2025-09-14 21:38:07.0290 - INFO - graphrag.logger.progress - extract graph progress: 42/42
2025-09-14 21:38:07.0348 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 1/820
2025-09-14 21:38:07.0349 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 2/820
2025-09-14 21:38:07.0349 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 3/820
2025-09-14 21:38:07.0349 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 4/820
2025-09-14 21:38:07.0349 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 5/820
2025-09-14 21:38:07.0349 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 6/820
2025-09-14 21:38:07.0349 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 7/820
2025-09-14 21:38:07.0349 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 8/820
2025-09-14 21:38:07.0349 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 9/820
2025-09-14 21:38:07.0349 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 10/820
2025-09-14 21:38:07.0349 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 11/820
2025-09-14 21:38:07.0350 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 12/820
2025-09-14 21:38:07.0350 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 13/820
2025-09-14 21:38:07.0351 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 14/820
2025-09-14 21:38:07.0352 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 15/820
2025-09-14 21:38:07.0353 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 16/820
2025-09-14 21:38:07.0353 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 17/820
2025-09-14 21:38:07.0353 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 18/820
2025-09-14 21:38:07.0353 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 19/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 20/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 21/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 22/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 23/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 24/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 25/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 26/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 27/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 28/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 29/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 30/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 31/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 32/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 33/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 34/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 35/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 36/820
2025-09-14 21:38:07.0354 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 37/820
2025-09-14 21:38:07.0355 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 38/820
2025-09-14 21:38:07.0355 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 39/820
2025-09-14 21:38:09.0175 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 40/820
2025-09-14 21:38:09.0175 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 41/820
2025-09-14 21:38:09.0175 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 42/820
2025-09-14 21:38:09.0175 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 43/820
2025-09-14 21:38:09.0175 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 44/820
2025-09-14 21:38:09.0175 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 45/820
2025-09-14 21:38:09.0175 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 46/820
2025-09-14 21:38:09.0175 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 47/820
2025-09-14 21:38:09.0176 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 48/820
2025-09-14 21:38:09.0176 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 49/820
2025-09-14 21:38:09.0176 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 50/820
2025-09-14 21:38:10.0494 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 51/820
2025-09-14 21:38:10.0494 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 52/820
2025-09-14 21:38:10.0495 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 53/820
2025-09-14 21:38:10.0495 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 54/820
2025-09-14 21:38:10.0495 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 55/820
2025-09-14 21:38:10.0495 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 56/820
2025-09-14 21:38:10.0495 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 57/820
2025-09-14 21:38:10.0495 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 58/820
2025-09-14 21:38:10.0642 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 59/820
2025-09-14 21:38:10.0658 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 60/820
2025-09-14 21:38:10.0658 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 61/820
2025-09-14 21:38:10.0659 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 62/820
2025-09-14 21:38:10.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 63/820
2025-09-14 21:38:10.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 64/820
2025-09-14 21:38:10.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 65/820
2025-09-14 21:38:10.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 66/820
2025-09-14 21:38:10.0698 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 67/820
2025-09-14 21:38:10.0698 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 68/820
2025-09-14 21:38:10.0698 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 69/820
2025-09-14 21:38:10.0698 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 70/820
2025-09-14 21:38:10.0698 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 71/820
2025-09-14 21:38:10.0699 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 72/820
2025-09-14 21:38:10.0699 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 73/820
2025-09-14 21:38:10.0742 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 74/820
2025-09-14 21:38:10.0755 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 75/820
2025-09-14 21:38:10.0755 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 76/820
2025-09-14 21:38:10.0755 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 77/820
2025-09-14 21:38:10.0755 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 78/820
2025-09-14 21:38:10.0755 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 79/820
2025-09-14 21:38:10.0755 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 80/820
2025-09-14 21:38:10.0755 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 81/820
2025-09-14 21:38:10.0755 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 82/820
2025-09-14 21:38:10.0756 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 83/820
2025-09-14 21:38:10.0823 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 84/820
2025-09-14 21:38:10.0843 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 85/820
2025-09-14 21:38:10.0844 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 86/820
2025-09-14 21:38:10.0881 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 87/820
2025-09-14 21:38:10.0881 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 88/820
2025-09-14 21:38:10.0881 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 89/820
2025-09-14 21:38:10.0881 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 90/820
2025-09-14 21:38:10.0881 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 91/820
2025-09-14 21:38:10.0881 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 92/820
2025-09-14 21:38:10.0882 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 93/820
2025-09-14 21:38:10.0882 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 94/820
2025-09-14 21:38:10.0882 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 95/820
2025-09-14 21:38:10.0882 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 96/820
2025-09-14 21:38:10.0882 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 97/820
2025-09-14 21:38:10.0882 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 98/820
2025-09-14 21:38:10.0882 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 99/820
2025-09-14 21:38:10.0882 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 100/820
2025-09-14 21:38:10.0883 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 101/820
2025-09-14 21:38:10.0883 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 102/820
2025-09-14 21:38:10.0883 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 103/820
2025-09-14 21:38:10.0883 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 104/820
2025-09-14 21:38:10.0883 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 105/820
2025-09-14 21:38:10.0883 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 106/820
2025-09-14 21:38:10.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 107/820
2025-09-14 21:38:10.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 108/820
2025-09-14 21:38:10.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 109/820
2025-09-14 21:38:10.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 110/820
2025-09-14 21:38:10.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 111/820
2025-09-14 21:38:10.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 112/820
2025-09-14 21:38:10.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 113/820
2025-09-14 21:38:10.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 114/820
2025-09-14 21:38:10.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 115/820
2025-09-14 21:38:10.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 116/820
2025-09-14 21:38:10.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 117/820
2025-09-14 21:38:10.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 118/820
2025-09-14 21:38:10.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 119/820
2025-09-14 21:38:10.0893 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 120/820
2025-09-14 21:38:10.0894 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 121/820
2025-09-14 21:38:10.0894 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 122/820
2025-09-14 21:38:10.0894 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 123/820
2025-09-14 21:38:10.0894 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 124/820
2025-09-14 21:38:10.0894 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 125/820
2025-09-14 21:38:10.0894 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 126/820
2025-09-14 21:38:10.0894 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 127/820
2025-09-14 21:38:10.0894 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 128/820
2025-09-14 21:38:10.0894 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 129/820
2025-09-14 21:38:10.0894 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 130/820
2025-09-14 21:38:10.0894 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 131/820
2025-09-14 21:38:10.0895 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 132/820
2025-09-14 21:38:10.0895 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 133/820
2025-09-14 21:38:10.0895 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 134/820
2025-09-14 21:38:10.0988 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 135/820
2025-09-14 21:38:10.0989 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 136/820
2025-09-14 21:38:10.0989 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 137/820
2025-09-14 21:38:10.0989 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 138/820
2025-09-14 21:38:10.0990 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 139/820
2025-09-14 21:38:10.0990 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 140/820
2025-09-14 21:38:10.0994 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 141/820
2025-09-14 21:38:10.0994 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 142/820
2025-09-14 21:38:10.0995 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 143/820
2025-09-14 21:38:11.0007 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 144/820
2025-09-14 21:38:11.0008 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 145/820
2025-09-14 21:38:11.0008 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 146/820
2025-09-14 21:38:11.0008 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 147/820
2025-09-14 21:38:11.0008 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 148/820
2025-09-14 21:38:11.0008 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 149/820
2025-09-14 21:38:11.0008 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 150/820
2025-09-14 21:38:11.0009 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 151/820
2025-09-14 21:38:11.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 152/820
2025-09-14 21:38:11.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 153/820
2025-09-14 21:38:11.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 154/820
2025-09-14 21:38:11.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 155/820
2025-09-14 21:38:11.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 156/820
2025-09-14 21:38:11.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 157/820
2025-09-14 21:38:11.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 158/820
2025-09-14 21:38:11.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 159/820
2025-09-14 21:38:11.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 160/820
2025-09-14 21:38:11.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 161/820
2025-09-14 21:38:11.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 162/820
2025-09-14 21:38:11.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 163/820
2025-09-14 21:38:11.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 164/820
2025-09-14 21:38:11.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 165/820
2025-09-14 21:38:11.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 166/820
2025-09-14 21:38:11.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 167/820
2025-09-14 21:38:11.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 168/820
2025-09-14 21:38:11.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 169/820
2025-09-14 21:38:11.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 170/820
2025-09-14 21:38:11.0269 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 171/820
2025-09-14 21:38:11.0269 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 172/820
2025-09-14 21:38:11.0270 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 173/820
2025-09-14 21:38:11.0270 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 174/820
2025-09-14 21:38:11.0270 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 175/820
2025-09-14 21:38:11.0270 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 176/820
2025-09-14 21:38:11.0301 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 177/820
2025-09-14 21:38:11.0541 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 178/820
2025-09-14 21:38:11.0541 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 179/820
2025-09-14 21:38:11.0541 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 180/820
2025-09-14 21:38:11.0541 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 181/820
2025-09-14 21:38:11.0728 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 182/820
2025-09-14 21:38:11.0729 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 183/820
2025-09-14 21:38:11.0729 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 184/820
2025-09-14 21:38:11.0729 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 185/820
2025-09-14 21:38:11.0730 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 186/820
2025-09-14 21:38:11.0764 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 187/820
2025-09-14 21:38:11.0764 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 188/820
2025-09-14 21:38:11.0765 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 189/820
2025-09-14 21:38:11.0765 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 190/820
2025-09-14 21:38:11.0765 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 191/820
2025-09-14 21:38:11.0931 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 192/820
2025-09-14 21:38:11.0931 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 193/820
2025-09-14 21:38:12.0165 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 194/820
2025-09-14 21:38:12.0286 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 195/820
2025-09-14 21:38:12.0286 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 196/820
2025-09-14 21:38:12.0287 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 197/820
2025-09-14 21:38:12.0287 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 198/820
2025-09-14 21:38:12.0287 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 199/820
2025-09-14 21:38:12.0287 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 200/820
2025-09-14 21:38:12.0288 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 201/820
2025-09-14 21:38:12.0288 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 202/820
2025-09-14 21:38:12.0288 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 203/820
2025-09-14 21:38:12.0288 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 204/820
2025-09-14 21:38:12.0288 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 205/820
2025-09-14 21:38:12.0289 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 206/820
2025-09-14 21:38:12.0289 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 207/820
2025-09-14 21:38:12.0289 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 208/820
2025-09-14 21:38:12.0289 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 209/820
2025-09-14 21:38:12.0289 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 210/820
2025-09-14 21:38:12.0289 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 211/820
2025-09-14 21:38:12.0290 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 212/820
2025-09-14 21:38:12.0290 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 213/820
2025-09-14 21:38:12.0290 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 214/820
2025-09-14 21:38:12.0290 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 215/820
2025-09-14 21:38:12.0290 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 216/820
2025-09-14 21:38:12.0290 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 217/820
2025-09-14 21:38:12.0291 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 218/820
2025-09-14 21:38:12.0291 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 219/820
2025-09-14 21:38:12.0291 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 220/820
2025-09-14 21:38:12.0291 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 221/820
2025-09-14 21:38:12.0291 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 222/820
2025-09-14 21:38:12.0291 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 223/820
2025-09-14 21:38:12.0291 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 224/820
2025-09-14 21:38:12.0291 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 225/820
2025-09-14 21:38:12.0291 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 226/820
2025-09-14 21:38:12.0292 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 227/820
2025-09-14 21:38:12.0351 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 228/820
2025-09-14 21:38:12.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 229/820
2025-09-14 21:38:12.0421 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 230/820
2025-09-14 21:38:12.0421 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 231/820
2025-09-14 21:38:12.0421 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 232/820
2025-09-14 21:38:12.0421 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 233/820
2025-09-14 21:38:12.0422 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 234/820
2025-09-14 21:38:12.0565 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 235/820
2025-09-14 21:38:12.0566 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 236/820
2025-09-14 21:38:12.0566 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 237/820
2025-09-14 21:38:12.0567 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 238/820
2025-09-14 21:38:12.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 239/820
2025-09-14 21:38:12.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 240/820
2025-09-14 21:38:12.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 241/820
2025-09-14 21:38:12.0577 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 242/820
2025-09-14 21:38:12.0578 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 243/820
2025-09-14 21:38:12.0578 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 244/820
2025-09-14 21:38:12.0578 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 245/820
2025-09-14 21:38:12.0653 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 246/820
2025-09-14 21:38:12.0654 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 247/820
2025-09-14 21:38:12.0654 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 248/820
2025-09-14 21:38:12.0654 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 249/820
2025-09-14 21:38:12.0655 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 250/820
2025-09-14 21:38:12.0751 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 251/820
2025-09-14 21:38:12.0752 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 252/820
2025-09-14 21:38:12.0752 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 253/820
2025-09-14 21:38:12.0752 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 254/820
2025-09-14 21:38:12.0752 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 255/820
2025-09-14 21:38:12.0753 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 256/820
2025-09-14 21:38:12.0753 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 257/820
2025-09-14 21:38:12.0753 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 258/820
2025-09-14 21:38:12.0753 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 259/820
2025-09-14 21:38:12.0753 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 260/820
2025-09-14 21:38:12.0754 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 261/820
2025-09-14 21:38:12.0754 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 262/820
2025-09-14 21:38:12.0754 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 263/820
2025-09-14 21:38:12.0904 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 264/820
2025-09-14 21:38:12.0904 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 265/820
2025-09-14 21:38:12.0927 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 266/820
2025-09-14 21:38:12.0928 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 267/820
2025-09-14 21:38:12.0928 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 268/820
2025-09-14 21:38:12.0928 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 269/820
2025-09-14 21:38:12.0928 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 270/820
2025-09-14 21:38:12.0928 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 271/820
2025-09-14 21:38:12.0928 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 272/820
2025-09-14 21:38:12.0928 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 273/820
2025-09-14 21:38:12.0928 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 274/820
2025-09-14 21:38:12.0928 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 275/820
2025-09-14 21:38:12.0929 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 276/820
2025-09-14 21:38:12.0929 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 277/820
2025-09-14 21:38:12.0929 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 278/820
2025-09-14 21:38:12.0929 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 279/820
2025-09-14 21:38:12.0929 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 280/820
2025-09-14 21:38:12.0929 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 281/820
2025-09-14 21:38:12.0929 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 282/820
2025-09-14 21:38:12.0929 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 283/820
2025-09-14 21:38:12.0929 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 284/820
2025-09-14 21:38:12.0930 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 285/820
2025-09-14 21:38:12.0930 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 286/820
2025-09-14 21:38:12.0930 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 287/820
2025-09-14 21:38:12.0930 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 288/820
2025-09-14 21:38:12.0930 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 289/820
2025-09-14 21:38:12.0930 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 290/820
2025-09-14 21:38:12.0930 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 291/820
2025-09-14 21:38:12.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 292/820
2025-09-14 21:38:12.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 293/820
2025-09-14 21:38:12.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 294/820
2025-09-14 21:38:12.0965 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 295/820
2025-09-14 21:38:12.0965 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 296/820
2025-09-14 21:38:12.0966 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 297/820
2025-09-14 21:38:12.0966 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 298/820
2025-09-14 21:38:12.0966 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 299/820
2025-09-14 21:38:12.0966 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 300/820
2025-09-14 21:38:12.0966 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 301/820
2025-09-14 21:38:12.0966 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 302/820
2025-09-14 21:38:12.0966 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 303/820
2025-09-14 21:38:12.0967 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 304/820
2025-09-14 21:38:12.0967 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 305/820
2025-09-14 21:38:12.0967 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 306/820
2025-09-14 21:38:12.0967 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 307/820
2025-09-14 21:38:12.0967 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 308/820
2025-09-14 21:38:12.0967 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 309/820
2025-09-14 21:38:13.0038 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 310/820
2025-09-14 21:38:13.0113 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 311/820
2025-09-14 21:38:13.0114 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 312/820
2025-09-14 21:38:13.0127 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 313/820
2025-09-14 21:38:13.0376 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 314/820
2025-09-14 21:38:13.0409 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 315/820
2025-09-14 21:38:13.0469 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 316/820
2025-09-14 21:38:13.0491 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 317/820
2025-09-14 21:38:13.0518 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 318/820
2025-09-14 21:38:13.0839 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 319/820
2025-09-14 21:38:13.0872 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 320/820
2025-09-14 21:38:13.0892 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 321/820
2025-09-14 21:38:14.0045 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 322/820
2025-09-14 21:38:14.0133 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 323/820
2025-09-14 21:38:14.0311 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 324/820
2025-09-14 21:38:14.0491 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 325/820
2025-09-14 21:38:14.0501 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 326/820
2025-09-14 21:38:14.0501 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 327/820
2025-09-14 21:38:14.0631 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 328/820
2025-09-14 21:38:14.0711 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 329/820
2025-09-14 21:38:14.0731 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 330/820
2025-09-14 21:38:14.0748 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 331/820
2025-09-14 21:38:14.0847 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 332/820
2025-09-14 21:38:15.0210 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 333/820
2025-09-14 21:38:15.0216 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 334/820
2025-09-14 21:38:15.0216 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 335/820
2025-09-14 21:38:15.0216 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 336/820
2025-09-14 21:38:15.0216 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 337/820
2025-09-14 21:38:15.0216 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 338/820
2025-09-14 21:38:15.0217 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 339/820
2025-09-14 21:38:15.0217 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 340/820
2025-09-14 21:38:15.0217 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 341/820
2025-09-14 21:38:15.0217 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 342/820
2025-09-14 21:38:15.0221 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 343/820
2025-09-14 21:38:15.0222 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 344/820
2025-09-14 21:38:15.0222 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 345/820
2025-09-14 21:38:15.0222 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 346/820
2025-09-14 21:38:15.0222 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 347/820
2025-09-14 21:38:15.0222 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 348/820
2025-09-14 21:38:15.0222 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 349/820
2025-09-14 21:38:15.0222 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 350/820
2025-09-14 21:38:15.0222 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 351/820
2025-09-14 21:38:15.0224 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 352/820
2025-09-14 21:38:15.0224 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 353/820
2025-09-14 21:38:15.0224 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 354/820
2025-09-14 21:38:15.0224 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 355/820
2025-09-14 21:38:15.0224 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 356/820
2025-09-14 21:38:15.0226 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 357/820
2025-09-14 21:38:15.0226 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 358/820
2025-09-14 21:38:15.0226 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 359/820
2025-09-14 21:38:15.0227 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 360/820
2025-09-14 21:38:15.0227 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 361/820
2025-09-14 21:38:15.0227 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 362/820
2025-09-14 21:38:15.0227 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 363/820
2025-09-14 21:38:15.0227 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 364/820
2025-09-14 21:38:15.0227 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 365/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 366/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 367/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 368/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 369/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 370/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 371/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 372/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 373/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 374/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 375/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 376/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 377/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 378/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 379/820
2025-09-14 21:38:15.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 380/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 381/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 382/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 383/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 384/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 385/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 386/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 387/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 388/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 389/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 390/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 391/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 392/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 393/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 394/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 395/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 396/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 397/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 398/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 399/820
2025-09-14 21:38:15.0229 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 400/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 401/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 402/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 403/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 404/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 405/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 406/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 407/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 408/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 409/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 410/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 411/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 412/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 413/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 414/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 415/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 416/820
2025-09-14 21:38:15.0230 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 417/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 418/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 419/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 420/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 421/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 422/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 423/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 424/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 425/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 426/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 427/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 428/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 429/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 430/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 431/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 432/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 433/820
2025-09-14 21:38:15.0231 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 434/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 435/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 436/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 437/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 438/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 439/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 440/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 441/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 442/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 443/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 444/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 445/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 446/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 447/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 448/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 449/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 450/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 451/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 452/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 453/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 454/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 455/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 456/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 457/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 458/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 459/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 460/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 461/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 462/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 463/820
2025-09-14 21:38:15.0232 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 464/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 465/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 466/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 467/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 468/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 469/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 470/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 471/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 472/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 473/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 474/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 475/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 476/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 477/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 478/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 479/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 480/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 481/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 482/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 483/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 484/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 485/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 486/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 487/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 488/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 489/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 490/820
2025-09-14 21:38:15.0233 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 491/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 492/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 493/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 494/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 495/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 496/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 497/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 498/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 499/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 500/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 501/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 502/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 503/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 504/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 505/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 506/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 507/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 508/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 509/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 510/820
2025-09-14 21:38:15.0234 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 511/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 512/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 513/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 514/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 515/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 516/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 517/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 518/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 519/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 520/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 521/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 522/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 523/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 524/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 525/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 526/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 527/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 528/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 529/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 530/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 531/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 532/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 533/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 534/820
2025-09-14 21:38:15.0235 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 535/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 536/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 537/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 538/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 539/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 540/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 541/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 542/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 543/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 544/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 545/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 546/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 547/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 548/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 549/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 550/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 551/820
2025-09-14 21:38:15.0236 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 552/820
2025-09-14 21:38:16.0504 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 553/820
2025-09-14 21:38:16.0504 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 554/820
2025-09-14 21:38:16.0505 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 555/820
2025-09-14 21:38:16.0505 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 556/820
2025-09-14 21:38:16.0505 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 557/820
2025-09-14 21:38:16.0505 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 558/820
2025-09-14 21:38:16.0505 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 559/820
2025-09-14 21:38:16.0506 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 560/820
2025-09-14 21:38:16.0506 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 561/820
2025-09-14 21:38:16.0509 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 562/820
2025-09-14 21:38:16.0510 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 563/820
2025-09-14 21:38:16.0524 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 564/820
2025-09-14 21:38:16.0524 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 565/820
2025-09-14 21:38:16.0578 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 566/820
2025-09-14 21:38:16.0579 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 567/820
2025-09-14 21:38:16.0579 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 568/820
2025-09-14 21:38:16.0579 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 569/820
2025-09-14 21:38:16.0580 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 570/820
2025-09-14 21:38:16.0580 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 571/820
2025-09-14 21:38:16.0580 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 572/820
2025-09-14 21:38:16.0580 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 573/820
2025-09-14 21:38:16.0581 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 574/820
2025-09-14 21:38:16.0581 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 575/820
2025-09-14 21:38:16.0581 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 576/820
2025-09-14 21:38:16.0581 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 577/820
2025-09-14 21:38:16.0581 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 578/820
2025-09-14 21:38:16.0582 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 579/820
2025-09-14 21:38:16.0582 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 580/820
2025-09-14 21:38:16.0582 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 581/820
2025-09-14 21:38:16.0583 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 582/820
2025-09-14 21:38:16.0583 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 583/820
2025-09-14 21:38:16.0583 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 584/820
2025-09-14 21:38:16.0584 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 585/820
2025-09-14 21:38:16.0584 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 586/820
2025-09-14 21:38:16.0584 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 587/820
2025-09-14 21:38:16.0584 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 588/820
2025-09-14 21:38:16.0584 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 589/820
2025-09-14 21:38:16.0584 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 590/820
2025-09-14 21:38:16.0585 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 591/820
2025-09-14 21:38:16.0585 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 592/820
2025-09-14 21:38:16.0585 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 593/820
2025-09-14 21:38:16.0644 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 594/820
2025-09-14 21:38:16.0644 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 595/820
2025-09-14 21:38:16.0644 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 596/820
2025-09-14 21:38:16.0645 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 597/820
2025-09-14 21:38:16.0645 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 598/820
2025-09-14 21:38:16.0645 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 599/820
2025-09-14 21:38:16.0645 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 600/820
2025-09-14 21:38:16.0646 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 601/820
2025-09-14 21:38:16.0646 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 602/820
2025-09-14 21:38:16.0646 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 603/820
2025-09-14 21:38:16.0646 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 604/820
2025-09-14 21:38:16.0656 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 605/820
2025-09-14 21:38:16.0656 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 606/820
2025-09-14 21:38:16.0656 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 607/820
2025-09-14 21:38:16.0656 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 608/820
2025-09-14 21:38:16.0656 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 609/820
2025-09-14 21:38:16.0666 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 610/820
2025-09-14 21:38:16.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 611/820
2025-09-14 21:38:16.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 612/820
2025-09-14 21:38:16.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 613/820
2025-09-14 21:38:16.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 614/820
2025-09-14 21:38:16.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 615/820
2025-09-14 21:38:16.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 616/820
2025-09-14 21:38:16.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 617/820
2025-09-14 21:38:16.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 618/820
2025-09-14 21:38:16.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 619/820
2025-09-14 21:38:16.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 620/820
2025-09-14 21:38:16.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 621/820
2025-09-14 21:38:16.0667 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 622/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 623/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 624/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 625/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 626/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 627/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 628/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 629/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 630/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 631/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 632/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 633/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 634/820
2025-09-14 21:38:16.0668 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 635/820
2025-09-14 21:38:16.0669 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 636/820
2025-09-14 21:38:16.0703 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 637/820
2025-09-14 21:38:16.0773 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 638/820
2025-09-14 21:38:16.0829 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 639/820
2025-09-14 21:38:16.0830 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 640/820
2025-09-14 21:38:16.0830 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 641/820
2025-09-14 21:38:16.0830 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 642/820
2025-09-14 21:38:16.0831 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 643/820
2025-09-14 21:38:16.0831 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 644/820
2025-09-14 21:38:16.0831 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 645/820
2025-09-14 21:38:16.0831 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 646/820
2025-09-14 21:38:16.0832 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 647/820
2025-09-14 21:38:16.0832 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 648/820
2025-09-14 21:38:16.0832 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 649/820
2025-09-14 21:38:16.0832 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 650/820
2025-09-14 21:38:16.0833 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 651/820
2025-09-14 21:38:16.0833 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 652/820
2025-09-14 21:38:16.0842 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 653/820
2025-09-14 21:38:16.0842 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 654/820
2025-09-14 21:38:16.0842 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 655/820
2025-09-14 21:38:16.0842 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 656/820
2025-09-14 21:38:16.0843 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 657/820
2025-09-14 21:38:16.0843 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 658/820
2025-09-14 21:38:16.0843 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 659/820
2025-09-14 21:38:16.0843 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 660/820
2025-09-14 21:38:16.0910 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 661/820
2025-09-14 21:38:16.0912 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 662/820
2025-09-14 21:38:16.0912 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 663/820
2025-09-14 21:38:16.0913 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 664/820
2025-09-14 21:38:16.0913 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 665/820
2025-09-14 21:38:16.0913 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 666/820
2025-09-14 21:38:16.0914 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 667/820
2025-09-14 21:38:16.0914 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 668/820
2025-09-14 21:38:16.0914 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 669/820
2025-09-14 21:38:16.0914 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 670/820
2025-09-14 21:38:16.0914 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 671/820
2025-09-14 21:38:16.0915 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 672/820
2025-09-14 21:38:16.0916 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 673/820
2025-09-14 21:38:16.0916 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 674/820
2025-09-14 21:38:16.0920 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 675/820
2025-09-14 21:38:16.0920 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 676/820
2025-09-14 21:38:16.0921 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 677/820
2025-09-14 21:38:16.0921 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 678/820
2025-09-14 21:38:16.0922 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 679/820
2025-09-14 21:38:16.0922 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 680/820
2025-09-14 21:38:16.0922 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 681/820
2025-09-14 21:38:16.0923 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 682/820
2025-09-14 21:38:16.0993 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 683/820
2025-09-14 21:38:16.0994 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 684/820
2025-09-14 21:38:16.0994 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 685/820
2025-09-14 21:38:16.0994 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 686/820
2025-09-14 21:38:16.0995 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 687/820
2025-09-14 21:38:16.0995 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 688/820
2025-09-14 21:38:16.0995 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 689/820
2025-09-14 21:38:16.0995 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 690/820
2025-09-14 21:38:16.0995 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 691/820
2025-09-14 21:38:16.0995 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 692/820
2025-09-14 21:38:16.0995 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 693/820
2025-09-14 21:38:16.0995 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 694/820
2025-09-14 21:38:16.0996 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 695/820
2025-09-14 21:38:16.0996 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 696/820
2025-09-14 21:38:16.0996 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 697/820
2025-09-14 21:38:16.0996 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 698/820
2025-09-14 21:38:16.0996 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 699/820
2025-09-14 21:38:16.0996 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 700/820
2025-09-14 21:38:16.0996 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 701/820
2025-09-14 21:38:16.0996 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 702/820
2025-09-14 21:38:16.0997 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 703/820
2025-09-14 21:38:16.0997 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 704/820
2025-09-14 21:38:16.0997 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 705/820
2025-09-14 21:38:16.0997 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 706/820
2025-09-14 21:38:16.0997 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 707/820
2025-09-14 21:38:16.0997 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 708/820
2025-09-14 21:38:16.0997 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 709/820
2025-09-14 21:38:16.0998 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 710/820
2025-09-14 21:38:16.0998 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 711/820
2025-09-14 21:38:16.0998 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 712/820
2025-09-14 21:38:16.0998 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 713/820
2025-09-14 21:38:16.0998 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 714/820
2025-09-14 21:38:16.0998 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 715/820
2025-09-14 21:38:16.0998 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 716/820
2025-09-14 21:38:16.0998 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 717/820
2025-09-14 21:38:16.0998 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 718/820
2025-09-14 21:38:16.0999 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 719/820
2025-09-14 21:38:16.0999 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 720/820
2025-09-14 21:38:16.0999 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 721/820
2025-09-14 21:38:16.0999 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 722/820
2025-09-14 21:38:16.0999 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 723/820
2025-09-14 21:38:16.0999 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 724/820
2025-09-14 21:38:17.0000 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 725/820
2025-09-14 21:38:17.0000 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 726/820
2025-09-14 21:38:17.0000 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 727/820
2025-09-14 21:38:17.0000 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 728/820
2025-09-14 21:38:17.0000 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 729/820
2025-09-14 21:38:17.0000 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 730/820
2025-09-14 21:38:17.0001 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 731/820
2025-09-14 21:38:17.0001 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 732/820
2025-09-14 21:38:17.0001 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 733/820
2025-09-14 21:38:17.0001 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 734/820
2025-09-14 21:38:17.0001 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 735/820
2025-09-14 21:38:17.0001 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 736/820
2025-09-14 21:38:17.0001 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 737/820
2025-09-14 21:38:17.0002 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 738/820
2025-09-14 21:38:17.0002 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 739/820
2025-09-14 21:38:17.0002 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 740/820
2025-09-14 21:38:17.0002 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 741/820
2025-09-14 21:38:17.0002 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 742/820
2025-09-14 21:38:17.0002 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 743/820
2025-09-14 21:38:17.0002 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 744/820
2025-09-14 21:38:17.0002 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 745/820
2025-09-14 21:38:17.0003 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 746/820
2025-09-14 21:38:17.0003 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 747/820
2025-09-14 21:38:17.0003 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 748/820
2025-09-14 21:38:17.0003 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 749/820
2025-09-14 21:38:17.0003 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 750/820
2025-09-14 21:38:17.0003 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 751/820
2025-09-14 21:38:17.0003 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 752/820
2025-09-14 21:38:17.0004 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 753/820
2025-09-14 21:38:17.0040 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 754/820
2025-09-14 21:38:17.0040 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 755/820
2025-09-14 21:38:17.0040 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 756/820
2025-09-14 21:38:17.0041 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 757/820
2025-09-14 21:38:17.0041 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 758/820
2025-09-14 21:38:17.0041 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 759/820
2025-09-14 21:38:17.0041 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 760/820
2025-09-14 21:38:17.0041 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 761/820
2025-09-14 21:38:17.0041 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 762/820
2025-09-14 21:38:17.0041 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 763/820
2025-09-14 21:38:17.0041 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 764/820
2025-09-14 21:38:17.0042 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 765/820
2025-09-14 21:38:17.0042 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 766/820
2025-09-14 21:38:17.0042 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 767/820
2025-09-14 21:38:17.0042 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 768/820
2025-09-14 21:38:17.0042 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 769/820
2025-09-14 21:38:17.0161 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 770/820
2025-09-14 21:38:17.0161 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 771/820
2025-09-14 21:38:17.0162 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 772/820
2025-09-14 21:38:17.0181 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 773/820
2025-09-14 21:38:17.0182 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 774/820
2025-09-14 21:38:17.0182 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 775/820
2025-09-14 21:38:17.0182 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 776/820
2025-09-14 21:38:17.0182 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 777/820
2025-09-14 21:38:17.0182 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 778/820
2025-09-14 21:38:17.0182 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 779/820
2025-09-14 21:38:17.0183 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 780/820
2025-09-14 21:38:17.0183 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 781/820
2025-09-14 21:38:17.0183 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 782/820
2025-09-14 21:38:17.0183 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 783/820
2025-09-14 21:38:17.0183 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 784/820
2025-09-14 21:38:17.0183 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 785/820
2025-09-14 21:38:17.0183 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 786/820
2025-09-14 21:38:17.0184 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 787/820
2025-09-14 21:38:17.0184 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 788/820
2025-09-14 21:38:17.0184 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 789/820
2025-09-14 21:38:17.0184 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 790/820
2025-09-14 21:38:17.0184 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 791/820
2025-09-14 21:38:17.0184 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 792/820
2025-09-14 21:38:17.0184 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 793/820
2025-09-14 21:38:17.0184 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 794/820
2025-09-14 21:38:17.0185 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 795/820
2025-09-14 21:38:17.0185 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 796/820
2025-09-14 21:38:17.0199 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 797/820
2025-09-14 21:38:17.0228 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 798/820
2025-09-14 21:38:17.0249 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 799/820
2025-09-14 21:38:17.0630 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 800/820
2025-09-14 21:38:17.0722 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 801/820
2025-09-14 21:38:17.0730 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 802/820
2025-09-14 21:38:17.0755 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 803/820
2025-09-14 21:38:17.0765 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 804/820
2025-09-14 21:38:17.0825 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 805/820
2025-09-14 21:38:17.0825 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 806/820
2025-09-14 21:38:17.0931 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 807/820
2025-09-14 21:38:18.0022 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 808/820
2025-09-14 21:38:18.0048 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 809/820
2025-09-14 21:38:18.0172 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 810/820
2025-09-14 21:38:18.0283 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 811/820
2025-09-14 21:38:18.0359 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 812/820
2025-09-14 21:38:18.0359 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 813/820
2025-09-14 21:38:18.0383 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 814/820
2025-09-14 21:38:18.0522 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 815/820
2025-09-14 21:38:18.0611 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 816/820
2025-09-14 21:38:18.0859 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 817/820
2025-09-14 21:38:18.0878 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 818/820
2025-09-14 21:38:18.0891 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 819/820
2025-09-14 21:38:19.0268 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 820/820
2025-09-14 21:38:19.0288 - INFO - graphrag.index.workflows.extract_graph - Workflow completed: extract_graph
2025-09-14 21:38:19.0288 - INFO - graphrag.api.index - Workflow extract_graph completed successfully
2025-09-14 21:38:19.0299 - INFO - graphrag.index.workflows.finalize_graph - Workflow started: finalize_graph
2025-09-14 21:38:19.0300 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-09-14 21:38:19.0303 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-09-14 21:38:19.0332 - INFO - graphrag.index.workflows.finalize_graph - Workflow completed: finalize_graph
2025-09-14 21:38:19.0332 - INFO - graphrag.api.index - Workflow finalize_graph completed successfully
2025-09-14 21:38:19.0339 - INFO - graphrag.index.workflows.extract_covariates - Workflow started: extract_covariates
2025-09-14 21:38:19.0339 - INFO - graphrag.index.workflows.extract_covariates - Workflow completed: extract_covariates
2025-09-14 21:38:19.0339 - INFO - graphrag.api.index - Workflow extract_covariates completed successfully
2025-09-14 21:38:19.0339 - INFO - graphrag.index.workflows.create_communities - Workflow started: create_communities
2025-09-14 21:38:19.0339 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-09-14 21:38:19.0341 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-09-14 21:38:19.0370 - INFO - graphrag.index.workflows.create_communities - Workflow completed: create_communities
2025-09-14 21:38:19.0371 - INFO - graphrag.api.index - Workflow create_communities completed successfully
2025-09-14 21:38:19.0388 - INFO - graphrag.index.workflows.create_final_text_units - Workflow started: create_final_text_units
2025-09-14 21:38:19.0388 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-14 21:38:19.0389 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-09-14 21:38:19.0391 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-09-14 21:38:19.0400 - INFO - graphrag.index.workflows.create_final_text_units - Workflow completed: create_final_text_units
2025-09-14 21:38:19.0400 - INFO - graphrag.api.index - Workflow create_final_text_units completed successfully
2025-09-14 21:38:19.0412 - INFO - graphrag.index.workflows.create_community_reports - Workflow started: create_community_reports
2025-09-14 21:38:19.0413 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-09-14 21:38:19.0414 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-09-14 21:38:19.0415 - INFO - graphrag.utils.storage - reading table from storage: communities.parquet
2025-09-14 21:38:19.0422 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=2 => 80
2025-09-14 21:38:19.0491 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=1 => 231
2025-09-14 21:38:19.0640 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=0 => 275
2025-09-14 21:38:44.0055 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 1/11
2025-09-14 21:38:51.0354 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 2/11
2025-09-14 21:38:52.0253 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 3/11
2025-09-14 21:38:54.0070 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 4/11
2025-09-14 21:38:54.0600 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 5/11
2025-09-14 21:38:54.0800 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 6/11
2025-09-14 21:38:54.0827 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 7/11
2025-09-14 21:38:55.0058 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 8/11
2025-09-14 21:38:56.0014 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 9/11
2025-09-14 21:38:56.0397 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 10/11
2025-09-14 21:38:57.0466 - INFO - graphrag.logger.progress - level 2 summarize communities progress: 11/11
2025-09-14 21:39:05.0053 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 1/31
2025-09-14 21:39:06.0282 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 2/31
2025-09-14 21:39:07.0307 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 3/31
2025-09-14 21:39:07.0339 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 4/31
2025-09-14 21:39:07.0712 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 5/31
2025-09-14 21:39:07.0972 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 6/31
2025-09-14 21:39:08.0995 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 7/31
2025-09-14 21:39:09.0468 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 8/31
2025-09-14 21:39:09.0848 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 9/31
2025-09-14 21:39:10.0673 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 10/31
2025-09-14 21:39:11.0094 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 11/31
2025-09-14 21:39:11.0408 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 12/31
2025-09-14 21:39:11.0503 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 13/31
2025-09-14 21:39:12.0293 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 14/31
2025-09-14 21:39:12.0310 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 15/31
2025-09-14 21:39:12.0834 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 16/31
2025-09-14 21:39:13.0655 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 17/31
2025-09-14 21:39:14.0083 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 18/31
2025-09-14 21:39:14.0565 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 19/31
2025-09-14 21:39:14.0779 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 20/31
2025-09-14 21:39:15.0805 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 21/31
2025-09-14 21:39:16.0273 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 22/31
2025-09-14 21:39:16.0325 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 23/31
2025-09-14 21:39:16.0531 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 24/31
2025-09-14 21:39:19.0490 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 25/31
2025-09-14 21:39:20.0606 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 26/31
2025-09-14 21:39:21.0118 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 27/31
2025-09-14 21:39:21.0347 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 28/31
2025-09-14 21:39:24.0516 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 29/31
2025-09-14 21:39:25.0356 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 30/31
2025-09-14 21:39:27.0572 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 31/31
2025-09-14 21:39:36.0110 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 1/18
2025-09-14 21:39:36.0588 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 2/18
2025-09-14 21:39:38.0634 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 3/18
2025-09-14 21:39:39.0482 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 4/18
2025-09-14 21:39:40.0141 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 5/18
2025-09-14 21:39:40.0316 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 6/18
2025-09-14 21:39:40.0450 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 7/18
2025-09-14 21:39:41.0497 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 8/18
2025-09-14 21:39:42.0134 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 9/18
2025-09-14 21:39:42.0520 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 10/18
2025-09-14 21:39:44.0061 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 11/18
2025-09-14 21:39:45.0709 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 12/18
2025-09-14 21:39:47.0216 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 13/18
2025-09-14 21:39:48.0870 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 14/18
2025-09-14 21:39:48.0951 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 15/18
2025-09-14 21:39:49.0593 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 16/18
2025-09-14 21:39:52.0146 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 17/18
2025-09-14 21:40:01.0174 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 18/18
2025-09-14 21:40:01.0193 - INFO - graphrag.index.workflows.create_community_reports - Workflow completed: create_community_reports
2025-09-14 21:40:01.0194 - INFO - graphrag.api.index - Workflow create_community_reports completed successfully
2025-09-14 21:40:01.0247 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow started: generate_text_embeddings
2025-09-14 21:40:01.0247 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-09-14 21:40:01.0250 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-09-14 21:40:01.0252 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-09-14 21:40:01.0254 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-09-14 21:40:01.0255 - INFO - graphrag.utils.storage - reading table from storage: community_reports.parquet
2025-09-14 21:40:01.0259 - INFO - graphrag.index.workflows.generate_text_embeddings - Creating embeddings
2025-09-14 21:40:01.0259 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding entity.description: default-entity-description
2025-09-14 21:40:01.0273 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-09-14 21:40:01.0289 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 313 inputs via 313 snippets using 20 batches. max_batch_size=16, batch_max_tokens=8191
2025-09-14 21:40:02.0576 - INFO - graphrag.logger.progress - generate embeddings progress: 1/20
2025-09-14 21:40:02.0654 - INFO - graphrag.logger.progress - generate embeddings progress: 2/20
2025-09-14 21:40:02.0655 - INFO - graphrag.logger.progress - generate embeddings progress: 3/20
2025-09-14 21:40:02.0697 - INFO - graphrag.logger.progress - generate embeddings progress: 4/20
2025-09-14 21:40:02.0699 - INFO - graphrag.logger.progress - generate embeddings progress: 5/20
2025-09-14 21:40:02.0713 - INFO - graphrag.logger.progress - generate embeddings progress: 6/20
2025-09-14 21:40:02.0892 - INFO - graphrag.logger.progress - generate embeddings progress: 7/20
2025-09-14 21:40:03.0010 - INFO - graphrag.logger.progress - generate embeddings progress: 8/20
2025-09-14 21:40:03.0292 - INFO - graphrag.logger.progress - generate embeddings progress: 9/20
2025-09-14 21:40:03.0294 - INFO - graphrag.logger.progress - generate embeddings progress: 10/20
2025-09-14 21:40:03.0344 - INFO - graphrag.logger.progress - generate embeddings progress: 11/20
2025-09-14 21:40:03.0360 - INFO - graphrag.logger.progress - generate embeddings progress: 12/20
2025-09-14 21:40:03.0378 - INFO - graphrag.logger.progress - generate embeddings progress: 13/20
2025-09-14 21:40:03.0405 - INFO - graphrag.logger.progress - generate embeddings progress: 14/20
2025-09-14 21:40:03.0466 - INFO - graphrag.logger.progress - generate embeddings progress: 15/20
2025-09-14 21:40:03.0467 - INFO - graphrag.logger.progress - generate embeddings progress: 16/20
2025-09-14 21:40:03.0530 - INFO - graphrag.logger.progress - generate embeddings progress: 17/20
2025-09-14 21:40:03.0714 - INFO - graphrag.logger.progress - generate embeddings progress: 18/20
2025-09-14 21:40:03.0994 - INFO - graphrag.logger.progress - generate embeddings progress: 19/20
2025-09-14 21:40:03.0996 - INFO - graphrag.logger.progress - generate embeddings progress: 20/20
2025-09-14 21:40:04.0066 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
2025-09-14 21:40:04.0067 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-09-14 21:40:04.0094 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 60 inputs via 60 snippets using 7 batches. max_batch_size=16, batch_max_tokens=8191
2025-09-14 21:40:05.0076 - INFO - graphrag.logger.progress - generate embeddings progress: 1/7
2025-09-14 21:40:05.0142 - INFO - graphrag.logger.progress - generate embeddings progress: 2/7
2025-09-14 21:40:05.0171 - INFO - graphrag.logger.progress - generate embeddings progress: 3/7
2025-09-14 21:40:05.0232 - INFO - graphrag.logger.progress - generate embeddings progress: 4/7
2025-09-14 21:40:05.0232 - INFO - graphrag.logger.progress - generate embeddings progress: 5/7
2025-09-14 21:40:05.0244 - INFO - graphrag.logger.progress - generate embeddings progress: 6/7
2025-09-14 21:40:05.0379 - INFO - graphrag.logger.progress - generate embeddings progress: 7/7
2025-09-14 21:40:05.0390 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
2025-09-14 21:40:05.0392 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-09-14 21:40:05.0429 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 42 inputs via 42 snippets using 7 batches. max_batch_size=16, batch_max_tokens=8191
2025-09-14 21:40:06.0118 - INFO - graphrag.logger.progress - generate embeddings progress: 1/7
2025-09-14 21:40:06.0190 - INFO - graphrag.logger.progress - generate embeddings progress: 2/7
2025-09-14 21:40:06.0372 - INFO - graphrag.logger.progress - generate embeddings progress: 3/7
2025-09-14 21:40:06.0423 - INFO - graphrag.logger.progress - generate embeddings progress: 4/7
2025-09-14 21:40:06.0435 - INFO - graphrag.logger.progress - generate embeddings progress: 5/7
2025-09-14 21:40:06.0444 - INFO - graphrag.logger.progress - generate embeddings progress: 6/7
2025-09-14 21:40:06.0546 - INFO - graphrag.logger.progress - generate embeddings progress: 7/7
2025-09-14 21:40:06.0555 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow completed: generate_text_embeddings
2025-09-14 21:40:06.0556 - INFO - graphrag.api.index - Workflow generate_text_embeddings completed successfully
2025-09-14 21:40:06.0606 - INFO - graphrag.index.run.run_pipeline - Indexing pipeline complete.
2025-09-14 21:40:06.0608 - INFO - graphrag.cli.index - All workflows completed successfully.
2025-09-14 21:40:43.0591 - WARNING - graphrag.query.context_builder.community_context - Warning: No community records added when building community context.
2025-09-14 21:40:43.0597 - WARNING - graphrag.query.structured_search.local_search.mixed_context - Reached token limit - reverting to previous context state
2025-09-14 21:40:55.0509 - INFO - graphrag.cli.query - Local Search Response:
### Who is Scrooge?

Ebenezer Scrooge is the central character in Charles Dickens' "A Christmas Carol." He is initially portrayed as a grasping, covetous old man, deeply focused on wealth and business, and known for his miserly and cold-hearted nature. Scrooge is the surviving partner of the firm Scrooge and Marley, a counting-house business in London. He is characterized by his harshness, stinginess, and lack of empathy, especially towards the poor and those around him. Physically, he is described as having a pointed nose, shriveled cheek, and wiry chin, reflecting his frosty demeanor. He is notably disdainful of Christmas, often calling it "Humbug," and prefers isolation over social warmth.

Throughout the story, Scrooge experiences supernatural visitations from the ghost of his former business partner, Jacob Marley, and three Spirits of Christmas Past, Present, and Yet to Come. These encounters force him to confront his life choices, the consequences of his greed, and the impact of his behavior on others. As a result, Scrooge undergoes a profound transformation, becoming generous, caring, and joyful, embracing the spirit of Christmas and kindness towards others, especially the Cratchit family and his nephew Fred [Data: Entities (19, 32, 273)].

### Main Relationships of Scrooge

- **Jacob Marley**: Marley is Scrooge's deceased former business partner whose ghost visits Scrooge to warn him about the consequences of a life without charity and compassion. Marley’s ghostly presence is pivotal in initiating Scrooge’s journey toward redemption [Data: Entities (85, 31); Relationships (88)].

- **Bob Cratchit**: Bob Cratchit is Scrooge’s clerk, who works under harsh conditions due to Scrooge’s stinginess. Despite Scrooge’s coldness, Bob is a kind and humble man supporting a family, including his frail son, Tiny Tim. Scrooge’s eventual generosity extends to Bob, including raising his salary [Data: Entities (37); Relationships (18)].

- **Fred (Scrooge’s Nephew)**: Fred is a cheerful and warm-hearted man who contrasts sharply with Scrooge’s initial coldness. He consistently invites Scrooge to join in Christmas celebrations and embodies the spirit of goodwill and family love. Fred’s kindness influences Scrooge’s transformation [Data: Entities (35, 13, 274); Relationships (12)].

- **The Ghosts (Spirits)**: Scrooge is visited by several supernatural spirits, including the Ghost of Christmas Past, Present, and Yet to Come, who guide him through reflections on his life and the consequences of his actions. These spirits are instrumental in prompting Scrooge’s change of heart [Data: Entities (89); Relationships (14, 110)].

- **Family Members**: Scrooge’s sister Fan and niece also appear in the narrative, representing familial warmth and affection that contrast with Scrooge’s early isolation. Fan is his sister, and his niece is lively and affectionate, participating in family Christmas celebrations [Data: Entities (23, 240); Relationships (23)].

- **Dick Wilkins**: A fellow apprentice and close companion from Scrooge’s youth, representing a part of his past before his transformation into a miserly businessman [Data: Entities (21); Relationships (20)].

### Summary

Ebenezer Scrooge is a complex character who evolves from a miserly, cold-hearted businessman into a warm, generous individual through supernatural intervention and self-reflection. His key relationships—with his former partner Marley, his clerk Bob Cratchit, his nephew Fred, and various spirits—highlight the themes of redemption, compassion, and the true spirit of Christmas that define the story [Data: Entities (19, 32, 85, 37, 35, 13, 89); Relationships (88, 18, 12, 14, 110)].

If you would like, I can provide more detailed information about any of these relationships or characters.
